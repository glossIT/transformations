{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18dd2fac-8811-42f4-b666-66e7679cfabf",
   "metadata": {},
   "source": [
    "Goal: with superusertoken; document ID and part IDS find all lines, where there are versions, extract all those versions and note the respective line ID down <br7>\n",
    "PREREQUISITES: Levensthein module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ccb0f109-be0d-43a7-906e-3c00fc47e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import Levenshtein\n",
    "import tablib "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f33732-40c8-4a2f-8c5a-1c0e5858017a",
   "metadata": {},
   "source": [
    "document/37/part/3965/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16813c74-d3bd-4871-9ec0-5ecbff005d3c",
   "metadata": {},
   "source": [
    "Needs: TOKEN; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "9ab0c95a-61d7-4eb0-b054-03200ac2838b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "token = '81f07dae0233034e62ef3e4881bed4f936e8258a'\n",
    "\n",
    "versionlist =[]\n",
    "overview = []\n",
    "\n",
    "response = requests.get('http://143.50.30.29:8080/api/', headers={'Authorization': 'Token ' + token})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "126a0b2b-c7b1-4d0b-9a4c-b4f3c27ad025",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def type_check(token, documentid, partsid):\n",
    "    \"\"\"This function tests, if the parameters have the right type. It will be called in the version extractor function to check for the right types and \n",
    "    and raises errors, when needed\"\"\"\n",
    "    if type(token) != str:\n",
    "        raise TypeError ('Tokenparameter must be a string!')\n",
    "    elif type(documentid) != int:\n",
    "        raise TypeError ('DocumentID must be an integer!')\n",
    "    elif type(partsid) != int:\n",
    "        raise TypeError ('Tokenparameter must be an integer!')\n",
    "    else: \n",
    "        print ('Parameters are all good!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "00cbc80e-e51d-4087-960d-8b9bf6e2bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def line_num(token, documentid, partsid, pagenum):\n",
    "    \"\"\"Gets the id of all the lines on a page and stores them in an empty list. If the statuscode 404 appears, it stopps and prints an ending message. Afterwards \n",
    "    the API points of the sites will be opened in a loop and if there are versions, those will be saved\"\"\"\n",
    "    linenum=[]    \n",
    "    api_url = 'http://143.50.30.29:8080/api/documents/'\n",
    "    url = api_url + str(documentid) + \"/parts/\" + str(partsid) + '/lines/?page=' + str(pagenum)\n",
    "    doc_response = requests.get(url, headers={'Authorization': 'Token ' + token})   \n",
    "    json = doc_response.json()\n",
    "    print('Grabbing page....')\n",
    "    if doc_response.status_code != 404:\n",
    "        for i in json['results']:\n",
    "            linenum.append(i['pk'])\n",
    "            #print(i['pk'])\n",
    "        pagenum = pagenum+1    \n",
    "        #print(pagenum)\n",
    "        line_num(token, documentid, partsid, pagenum)      \n",
    "    else:\n",
    "        print('All pagenumbers collected. Last page reached.')\n",
    "    for i in linenum:\n",
    "        url = api_url + str(documentid) + \"/parts/\" + str(partsid) + '/lines/' +  str(i)    \n",
    "        resp = requests.get(url, headers={'Authorization': 'Token ' + token})\n",
    "        data = resp.json()\n",
    "        linevers = []  \n",
    "        order = data['order'] + 1\n",
    "        linevers.append(order)        \n",
    "        for transcription in data['transcriptions']:          \n",
    "           if transcription['versions'] != []:\n",
    "               current = transcription['content'] #version data to list \n",
    "               current_version = '\\n'+ \"Current Version:    \" + transcription['content']   + '\\n'             \n",
    "               filename = 'document-' + str(documentid) + '-part-' + str(partsid) + '.txt'\n",
    "               with open(filename,  'a', encoding=\"utf-8\") as f: \n",
    "                    f.write(current_version)  \n",
    "               linevers.append(current)\n",
    "               for versions in transcription['versions']:                 \n",
    "                   a = versions['data']['content']\n",
    "                   linevers.append(a)                   \n",
    "                   version = 'Older Version:      ' + versions['data']['content'] + '\\n'\n",
    "                   date = '------> Date:        '+ versions['updated_at'] + ' ' + '\\n'\n",
    "                   #print('Versionscontent: ', versions['data']['content'], ' Author:     ', versions['author'], '  Date:    ', versions['updated_at'])         \n",
    "                   with open(filename,  'a', encoding=\"utf-8\") as f: \n",
    "                        f.write(version + date)   \n",
    "               versionlist.append(linevers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5129df38-8ef0-46a7-9fe9-b959538873f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"extracts versions as a dirty txt file and fills in lists for further processing\"\"\"\n",
    "def version_extractor(token: str, documentid: int, partsid: int):      \n",
    "    type_check(token, documentid, partsid)\n",
    "    api_url = 'http://143.50.30.29:8080/api/documents/'\n",
    "    name = api_url + str(documentid)\n",
    "    overview.append(name)\n",
    "    line_num(token, documentid, partsid, 1)\n",
    "    print('Data extracted and saved as TXT.')\n",
    "    print('Starting CSV building...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "b419899f-28f4-4bfc-a8e5-fa34b7e00ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters are all good!\n",
      "Grabbing page....\n",
      "Grabbing page....\n",
      "Grabbing page....\n",
      "Grabbing page....\n",
      "Grabbing page....\n",
      "Grabbing page....\n",
      "Grabbing page....\n",
      "Grabbing page....\n",
      "Grabbing page....\n",
      "Grabbing page....\n",
      "Grabbing page....\n",
      "Grabbing page....\n",
      "Grabbing page....\n",
      "Grabbing page....\n",
      "Grabbing page....\n",
      "All pagenumbers collected. Last page reached.\n",
      "Data extracted and saved as TXT.\n",
      "Starting CSV building...\n"
     ]
    }
   ],
   "source": [
    "version_extractor(token, 10, 1502) # get all line numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2d7870-ff8d-4b5f-896e-d3b869eb1678",
   "metadata": {},
   "source": [
    "/lines --> hat count aller aller lines; 10 pro seite; results/pk is die jeweilige line num; \n",
    "in den lines gibts versions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "843c8470-cb9b-4334-9ea2-0ee4023ee636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d8c4ec81-c61c-48b0-8d71-79109ac7205e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://143.50.30.29:8080/api/documents/4']\n"
     ]
    }
   ],
   "source": [
    "print(overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d5fef2f3-5d3e-403f-9a30-ef47173941de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in linenum:\\n    url = api_url + str(37) + \"/parts/\" + str(3965) + \\'/lines/\\' +  str(i)\\n    \\n    resp = requests.get(url, headers={\\'Authorization\\': \\'Token \\' + token})\\n    data = resp.json()\\n    for transcription in data[\\'transcriptions\\']:\\n       if transcription[\\'versions\\'] != []:\\n           #print(transcription)\\n           print(\\'_________________________________________\\')\\n           print (\\'Current Version:    \\', transcription[\\'content\\'], \\'Author:      \\', transcription[\\'version_author\\'] )\\n           for versions in transcription[\\'versions\\']:\\n               print(\\'Versionscontent: \\', versions[\\'data\\'][\\'content\\'], \\' Author:     \\', versions[\\'author\\'], \\'  Date:    \\', versions[\\'updated_at\\'])   \\n           \\n           \\n           \\n          # print(\\'empty\\')\\n\\n           \\n             \\n         \\n   # print(check[\\'transcriptions\\'])\\n    #print(api_url + str(37) + \"/parts/\" + str(3965) + \\'/lines/\\' +  str(i))'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for i in linenum:\n",
    "    url = api_url + str(37) + \"/parts/\" + str(3965) + '/lines/' +  str(i)\n",
    "    \n",
    "    resp = requests.get(url, headers={'Authorization': 'Token ' + token})\n",
    "    data = resp.json()\n",
    "    for transcription in data['transcriptions']:\n",
    "       if transcription['versions'] != []:\n",
    "           #print(transcription)\n",
    "           print('_________________________________________')\n",
    "           print ('Current Version:    ', transcription['content'], 'Author:      ', transcription['version_author'] )\n",
    "           for versions in transcription['versions']:\n",
    "               print('Versionscontent: ', versions['data']['content'], ' Author:     ', versions['author'], '  Date:    ', versions['updated_at'])   \n",
    "           \n",
    "           \n",
    "           \n",
    "          # print('empty')\n",
    "\n",
    "           \n",
    "             \n",
    "         \n",
    "   # print(check['transcriptions'])\n",
    "    #print(api_url + str(37) + \"/parts/\" + str(3965) + '/lines/' +  str(i))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1cba0ef7-d9cb-4ccf-82e2-c4946e1dd083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'liste = []\\n\\nfor z in range(len(versionlist)):\\n    liste.append(z)\\n\\nprint(liste)'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"liste = []\n",
    "\n",
    "for z in range(len(versionlist)):\n",
    "    liste.append(z)\n",
    "\n",
    "print(liste)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "132ceedb-460d-44ef-878c-6857343d1b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "print(len(versionlist))\n",
    "DBLIST = tablib.Dataset(headers=['Current Version','Initial Version', 'Line number', 'Levenshtein Distance', 'Similarity Ratio'])\n",
    "for index in range(len(versionlist)):\n",
    "    order = versionlist[index][0]\n",
    "    currentversion = versionlist[index][1]\n",
    "    startversion = versionlist[index][-1]\n",
    "    dist_calc = Levenshtein.distance(currentversion, startversion)    \n",
    "    similarity_ratio = Levenshtein.ratio(currentversion, startversion)    \n",
    "    DBLIST.append([currentversion, startversion, order, dist_calc, similarity_ratio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e265de50-f799-4da7-9bb9-3638824f2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glossit.csv',  'w', encoding=\"utf-8\") as f:\n",
    "    f.write(DBLIST.export('csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79426c-b473-434e-89a9-e726901e91a4",
   "metadata": {},
   "source": [
    "* Document Name\n",
    "* Page ID\n",
    "* Link \n",
    "* wie viele lines gesamt und wie viele mussten ge√§ndert werden\n",
    "* Prozentsatz \n",
    "* erste und letzte iteration\n",
    "* levensthein Distance zwischen den iterationen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5697f1a1-253f-45d4-bbd8-a51e86c11301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.63451776649747\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "71c52103-48f7-4d20-8af9-70c7fe434cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a332784-71a9-4230-a366-c65e1ea082f8",
   "metadata": {},
   "source": [
    "* feinschliff - es wird nur die document ID gebraucht um einen umfassenden overview zu geben\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7821af12-ad9a-4d7a-9775-5fd291b84e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
